# Prepare the input message
# 1. System message: prompt
# 2. User message:  image + text

# Send it to llm via llm_inference_service

# Store the response in csv
# ImageID | ModelID | PromptID | Response

# ImageID = foldername-filenamewithoutExtension
# PromptID = 